<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>S·ªï Tay L·ªánh Tri·ªÉn Khai Hadoop 3.3.6</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; padding: 20px; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #2980b9; margin-top: 30px; }
        h3 { color: #2980b9; margin-top: 25px; }
        hr { border: 0; border-top: 1px solid #ecf0f1; margin: 20px 0; }
        p { margin-bottom: 15px; }
        /* Style cho b·∫£ng l·ªánh (gi·ªëng trang t√≠nh) */
        table { width: 100%; border-collapse: collapse; margin-top: 20px; table-layout: fixed; }
        th, td { border: 1px solid #bdc3c7; padding: 8px; text-align: left; word-wrap: break-word; font-size: 14px; }
        th { background-color: #3498db; color: white; font-weight: bold; }
        tr:nth-child(even) { background-color: #f8f9fa; }
        .command-group { background-color: #2980b9 !important; color: white !important; font-weight: bold; text-align: center; }
        /* Style cho kh·ªëi Tech Stack */
        .tech-stack { padding: 15px; background-color: #ecf0f1; border-radius: 8px; margin-top: 20px; }
        .tech-icons { display: flex; gap: 20px; flex-wrap: wrap; margin-top: 10px; }
        .tech-icon { text-align: center; font-size: 14px; }
        .tech-icon i { font-size: 24px; color: #2c3e50; margin-bottom: 5px; }
        /* Th√™m style cho code trong b·∫£ng */
        code { background-color: #eee; padding: 2px 4px; border-radius: 3px; font-family: monospace; font-size: 13px; }
        pre { background-color: #2c3e50; color: #ecf0f1; padding: 10px; border-radius: 5px; overflow-x: auto; }
        pre code { background-color: transparent; color: inherit; padding: 0; border-radius: 0; font-size: 14px; }
    </style>
</head>
<body>

<h1 style="color: red;">üìú S·ªï Tay L·ªánh C√†i ƒê·∫∑t & V·∫≠n H√†nh Hadoop 3.3.6 (Single Node)</h1>
<p>Ch√†o m·ª´ng ƒë·∫øn v·ªõi b·∫£ng t·ªïng h·ª£p c√°c l·ªánh c·∫ßn thi·∫øt ƒë·ªÉ tri·ªÉn khai h·ªá th·ªëng **Hadoop 3.3.6** tr√™n m√¥i tr∆∞·ªùng **Ubuntu/WSL2**. ƒê√¢y l√† phi√™n b·∫£n t·ªëi gi·∫£n nh·∫•t, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ anh d·ªÖ d√†ng in ra ho·∫∑c theo d√µi tr√™n m·ªôt trang.</p>

<div class="tech-stack">
    <h2>C√¥ng Ngh·ªá S·ª≠ D·ª•ng</h2>
    <p>Qu√° tr√¨nh n√†y ƒë√≤i h·ªèi s·ª± ph·ªëi h·ª£p c·ªßa c√°c c√¥ng ngh·ªá n·ªÅn t·∫£ng sau:</p>
    <div class="tech-icons">
        <div class="tech-icon">
            <i class="fab fa-linux"></i>
            <span>WSL2 / Linux (Ubuntu)</span>
        </div>
        <div class="tech-icon">
            <i class="fab fa-java"></i>
            <span>OpenJDK 8 (Java)</span>
        </div>
        <div class="tech-icon">
            <i class="fas fa-cubes"></i>
            <span>HDFS & YARN (Hadoop Core)</span>
        </div>
        <div class="tech-icon">
            <i class="fas fa-lock"></i>
            <span>SSH (Kh√¥ng M·∫≠t Kh·∫©u)</span>
        </div>
    </div>
</div>

<hr>

<h2>I. B·∫£ng T·ªïng H·ª£p L·ªánh Theo Tr√¨nh T·ª±</h2>

<table>
    <thead>
        <tr>
            <th>STT</th>
            <th>C√∫ ph√°p L·ªánh</th>
            <th>√ù nghƒ©a (M·ª•c ƒë√≠ch)</th>
        </tr>
    </thead>
    <tbody>
        <tr class="command-group">
            <td colspan="3">I. C√ÄI ƒê·∫∂T & CHU·∫®N B·ªä (Java, SSH)</td>
        </tr>
        <tr>
            <td>1.</td>
            <td><code>wsl --install</code></td>
            <td>C√†i ƒë·∫∑t WSL2 v√† phi√™n b·∫£n Ubuntu m·∫∑c ƒë·ªãnh (Ch·∫°y trong PowerShell/CMD).</td>
        </tr>
        <tr>
            <td>2.</td>
            <td><code>sudo apt install openjdk-8-jdk -y</code></td>
            <td>C√†i ƒë·∫∑t b·ªô c√¥ng c·ª• ph√°t tri·ªÉn Java 8 (B·∫Øt bu·ªôc cho Hadoop).</td>
        </tr>
        <tr>
            <td>3.</td>
            <td><code>ssh-keygen -t rsa -P ""</code></td>
            <td>T·∫°o c·∫∑p kh√≥a SSH kh√¥ng m·∫≠t kh·∫©u.</td>
        </tr>
        <tr>
            <td>4.</td>
            <td><code>cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys</code></td>
            <td>·ª¶y quy·ªÅn cho **Passwordless SSH**.</td>
        </tr>
        <tr>
            <td>5.</td>
            <td><code>ssh -o StrictHostKeyChecking=no localhost</code></td>
            <td>Ki·ªÉm tra k·∫øt n·ªëi SSH.</td>
        </tr>
        <tr class="command-group">
            <td colspan="3">II. L·∫ÆP ƒê·∫∂T V√Ä C·∫§U H√åNH C∆† B·∫¢N</td>
        </tr>
        <tr>
            <td>6.</td>
            <td><code>wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz</code></td>
            <td>T·∫£i file n√©n Hadoop 3.3.6 binary.</td>
        </tr>
        <tr>
            <td>7.</td>
            <td><code>sudo mv hadoop-3.3.6 /usr/local/hadoop</code></td>
            <td>Di chuy·ªÉn v√† ƒë·ªïi t√™n th∆∞ m·ª•c c√†i ƒë·∫∑t.</td>
        </tr>
        <tr>
            <td>8.</td>
            <td><code>sudo chown -R $USER:$USER /usr/local/hadoop</code></td>
            <td>C·∫•p quy·ªÅn s·ªü h·ªØu th∆∞ m·ª•c Hadoop cho t√†i kho·∫£n hi·ªán t·∫°i.</td>
        </tr>
        <tr>
            <td>9.</td>
            <td><code>nano ~/.bashrc</code></td>
            <td>M·ªü file c·∫•u h√¨nh bi·∫øn m√¥i tr∆∞·ªùng (`HADOOP_HOME`, `JAVA_HOME`, `PATH`).</td>
        </tr>
        <tr>
            <td>10.</td>
            <td><code>source ~/.bashrc</code></td>
            <td>T·∫£i l·∫°i c·∫•u h√¨nh m√¥i tr∆∞·ªùng.</td>
        </tr>
        <tr>
            <td>11.</td>
            <td><code>nano core-site.xml</code>, <code>hdfs-site.xml</code>, v.v.</td>
            <td>M·ªü c√°c file c·∫•u h√¨nh XML ch√≠nh ƒë·ªÉ thi·∫øt l·∫≠p NameNode v√† DataNode.</td>
        </tr>
        <tr>
            <td>12.</td>
            <td><code>hdfs namenode -format</code></td>
            <td>**ƒê·ªãnh d·∫°ng NameNode** (CH·ªà CH·∫†Y 1 L·∫¶N) ƒë·ªÉ kh·ªüi t·∫°o HDFS.</td>
        </tr>
        <tr class="command-group">
            <td colspan="3">III. V·∫¨N H√ÄNH & KI·ªÇM TH·ª¨ JOB</td>
        </tr>
        <tr>
            <td>13.</td>
            <td><code>stop-all.sh</code></td>
            <td>D·ª´ng t·∫•t c·∫£ c√°c d·ªãch v·ª• Hadoop (HDFS v√† YARN).</td>
        </tr>
        <tr>
            <td>14.</td>
            <td><code>start-all.sh</code></td>
            <td>Ch·∫°y to√†n b·ªô h·ªá th·ªëng c·ª•m Hadoop.</td>
        </tr>
        <tr>
            <td>15.</td>
            <td><code>jps</code></td>
            <td>Ki·ªÉm tra ti·∫øn tr√¨nh (X√°c nh·∫≠n 5 Daemon c·ªßa Hadoop ƒëang ch·∫°y).</td>
        </tr>
        <tr>
            <td>16.</td>
            <td><code>hdfs dfs -mkdir -p /user/$(whoami)</code></td>
            <td>T·∫°o th∆∞ m·ª•c l√†m vi·ªác tr√™n **HDFS**.</td>
        </tr>
        <tr>
            <td>17.</td>
            <td><code>hdfs dfs -put /tmp/my_input.txt /user/$(whoami)/input/</code></td>
            <td>**Upload** file d·ªØ li·ªáu t·ª´ Linux c·ª•c b·ªô v√†o HDFS.</td>
        </tr>
        <tr>
            <td>18.</td>
            <td><code>hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount /user/$(whoami)/input /user/$(whoami)/output_4</code></td>
            <td>**Ch·∫°y Job WordCount** (Job x·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu ti√™n).</td>
        </tr>
        <tr>
            <td>19.</td>
            <td><code>hdfs dfs -cat /user/$(whoami)/output_4/part-r-00000</code></td>
            <td>**Xem** n·ªôi dung c·ªßa file k·∫øt qu·∫£ tr√™n HDFS.</td>
        </tr>
        <tr class="command-group">
            <td colspan="3">IV. THAO T√ÅC NANO & C√ö PH√ÅP CHUNG</td>
        </tr>
        <tr>
            <td>20.</td>
            <td><code>Ctrl + O /+ Enter</code></td>
            <td>L∆∞u c√°c thay ƒë·ªïi trong `nano`.</td>
        </tr>
        <tr>
            <td>21.</td>
            <td><code>Ctrl + X</code></td>
            <td>Tho√°t kh·ªèi `nano`.</td>
        </tr>
        <tr>
            <td>22.</td>
            <td><code>hdfs dfs -rm -r /user/$(whoami)/output_4</code></td>
            <td>**X√≥a** th∆∞ m·ª•c output tr√™n HDFS (B·∫Øt bu·ªôc tr∆∞·ªõc khi ch·∫°y l·∫°i Job).</td>
        </tr>
    </tbody>
</table>

<hr>

<h2>II. H∆∞·ªõng D·∫´n Kh·ªüi ƒê·ªông L·∫°i H·ªá Th·ªëng</h2>

<h3>1. Kh·ªüi ƒë·ªông M√¥i tr∆∞·ªùng Ubuntu (WSL2)</h3>
<p>M·ªü CMD ho·∫∑c PowerShell v√† g√µ l·ªánh:</p>
<pre><code>wsl</code></pre>

<h3>2. Ki·ªÉm tra v√† Kh·ªüi ƒë·ªông D·ªãch v·ª• Hadoop</h3>
<p>Sau khi v√†o terminal Ubuntu, anh th·ª±c hi·ªán chu·ªói l·ªánh sau:</p>

<h4>2.1. Ki·ªÉm tra tr·∫°ng th√°i v√† Kh·ªüi ƒë·ªông</h4>
<p>Ch·∫°y <code>jps</code> ƒë·ªÉ ki·ªÉm tra. N·∫øu thi·∫øu ti·∫øn tr√¨nh, ch·∫°y l·ªánh kh·ªüi ƒë·ªông:</p>
<pre><code>start-all.sh</code></pre>

<h4>2.2. T·∫Øt To√†n b·ªô H·ªá th·ªëng (Khi D√πng Xong)</h4>
<p>ƒê·ªÉ ti·∫øt ki·ªám t√†i nguy√™n m√°y t√≠nh, anh n√™n t·∫Øt h·∫≥n Hadoop v√† ti·∫øn tr√¨nh WSL2:</p>
<ul>
    <li>**T·∫Øt Hadoop (Trong Ubuntu):**</li>
    <pre><code>stop-all.sh</code></pre>
    <li>**T·∫Øt WSL2 (Trong CMD/PowerShell Windows):**</li>
    <pre><code>wsl --shutdown</code></pre>
</ul>

<hr>

<img src="./images/hdsd_hadoop3.png" alt="·∫¢nh ch·∫°y th√†nh c√¥ng Hadoop" style="max-width: 80%; display: block; margin: 20px auto;">

</body>
</html>